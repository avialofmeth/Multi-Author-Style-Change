{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "In this file we will fine-tune Encoder models, like BERET, RoBERTa, etc., on the corpus of PAN. Then, evaluate them on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, DataCollatorWithPadding, utils\n",
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torchmetrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bertviz import model_view\n",
    "from datasets import Dataset\n",
    "from bertviz import head_view\n",
    "import wandb\n",
    "\n",
    "from utilities import (read_paragraphs,\n",
    "                       read_ground_truth, \n",
    "                       generate_dataset)\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'train_embeddings.npy' exists.\n"
     ]
    }
   ],
   "source": [
    "train_directory = './data/train_processed'\n",
    "train_label_directory = './data/train_label'\n",
    "test_directory = './data/validation_processed'\n",
    "test_label_directory = './data/validation_label'\n",
    "checkpoint = \"finetuned-bert-base-cased/sweep-1-checkpoint-225\" \n",
    "# File path to check\n",
    "train_embedding_file_path = \"train_embeddings.npy\"\n",
    "val_embedding_file_path   = \"val_embeddings.npy\"\n",
    "test_embedding_file_path  = \"test_embeddings.npy\"\n",
    "\n",
    "# hyperparameters of Random Forest Classifier\n",
    "opt_n_estimators=600 \n",
    "opt_random_state = 42\n",
    "sweep = False\n",
    "\n",
    "file_exists = False\n",
    "# Check if file exists\n",
    "if os.path.isfile(train_embedding_file_path):\n",
    "  file_exists = True\n",
    "  print(f\"File '{train_embedding_file_path}' exists.\")\n",
    "else:\n",
    "  print(f\"File '{train_embedding_file_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c19ac64fdf245709deb1b59d5dafd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfbbe45ccae4a41bd5f48d62e9560d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ec929353724871995bed9a72fe8c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 17530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 4383\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 4592\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read documents\n",
    "train_data = read_paragraphs(train_directory, start_id=1, end_id=4200) # {'problem-x': [sen 1, sen 2, ...], ...}\n",
    "test_data = read_paragraphs(test_directory, start_id=1, end_id=900)\n",
    "# Read ground truth labels\n",
    "train_labels = read_ground_truth(train_label_directory, start_id=1, end_id=4200) # {'problem-x': [1, ...], ...}\n",
    "test_labels  = read_ground_truth(test_label_directory, start_id=1, end_id=900)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "train_dataset = generate_dataset(train_data, train_labels, tokenizer)\n",
    "test_dataset = generate_dataset(test_data, test_labels, tokenizer)\n",
    "training_sets = train_dataset.train_test_split(train_size=0.8, seed=42)\n",
    "# Rename the default \"test\" split to \"validation\"\n",
    "training_sets[\"validation\"] = training_sets.pop(\"test\")\n",
    "# Add the \"test\" set to our `DatasetDict`\n",
    "training_sets[\"test\"] = test_dataset\n",
    "# print(training_sets)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], \n",
    "                    truncation=True)\n",
    "\n",
    "tokenized_datasets = training_sets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(tokenized_datasets)\n",
    "del training_sets, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else  'cpu')\n",
    "\n",
    "if not file_exists:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2, output_hidden_states=True)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not file_exists:\n",
    "def get_embeddings(bert_model, dataset, file_name, save=True):\n",
    "    # Calculate classification logits\n",
    "    batch_size=100\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in range(0, dataset.num_rows, batch_size): # \n",
    "                input_ids = {k:v for k, v in dataset[batch: batch + batch_size].items() if k not in ['sentence1', 'sentence2', 'idx']}\n",
    "                batch_data = data_collator(input_ids)\n",
    "                batch_data = {k:v.to(device) for k, v in batch_data.items()}\n",
    "                outputs = bert_model(**batch_data)\n",
    "                embeddings.append(outputs.hidden_states[-1][:, 0, :].detach().cpu().numpy().copy())\n",
    "                del outputs\n",
    "                # break\n",
    "\n",
    "    concatenated_embeddings = np.concatenate(embeddings, axis=0)\n",
    "    print(concatenated_embeddings.shape)\n",
    "    if save:\n",
    "        np.save(file_name, concatenated_embeddings)\n",
    "    else:\n",
    "        return concatenated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_exists:\n",
    "    get_embeddings(model, tokenized_datasets['test'], test_embedding_file_path)\n",
    "    np.save('test_labels.npy', np.array(tokenized_datasets['test']['label']))\n",
    "    get_embeddings(model, tokenized_datasets['validation'], val_embedding_file_path)\n",
    "    np.save('val_labels.npy', np.array(tokenized_datasets['validation']['label']))\n",
    "    get_embeddings(model, tokenized_datasets['train'], train_embedding_file_path)\n",
    "    np.save('train_labels.npy', np.array(tokenized_datasets['train']['label']))\n",
    "else:\n",
    "    test_embedding  = np.load(test_embedding_file_path)\n",
    "    val_embedding   = np.load(val_embedding_file_path)\n",
    "    train_embedding = np.load(train_embedding_file_path)\n",
    "\n",
    "    test_labels  = np.load('test_labels.npy')\n",
    "    val_labels   = np.load('val_labels.npy')\n",
    "    train_labels = np.load('train_labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sweep:\n",
    "    # hyper-parameter search, using sweep\n",
    "    sweep_config = {\n",
    "                    'method': 'bayes',\n",
    "                    'metric': {'goal': 'maximize', 'name': 'eval/F1'},\n",
    "                    'parameters': {\n",
    "                        'n_estimators': {\n",
    "                            'values': [100, 200, 300, 400, 500, 600],\n",
    "                        },\n",
    "                        'random_state': {'distribution': 'int_uniform',\n",
    "                                        'max': 50,\n",
    "                                        'min': 1,\n",
    "                        }\n",
    "                    }\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"multi_author_random_forest_sweep\")\n",
    "\n",
    "    def train(config=None):\n",
    "        with wandb.init(config=config):\n",
    "            # set sweep configuration\n",
    "            config = wandb.config\n",
    "            clf = RandomForestClassifier(n_estimators=config.n_estimators, random_state=config.random_state)\n",
    "            \n",
    "            clf.fit(train_embedding, train_labels) # X (n_samples, n_features)\n",
    "            y_pred = clf.predict(val_embedding)\n",
    "\n",
    "            wandb.log({'eval/F1': f1_score(val_labels, y_pred)})\n",
    "\n",
    "    wandb.agent(sweep_id, train, count=10)\n",
    "\n",
    "    # Best performance: F1: 0.7884, n_estimators=600, random_state = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(checkpoint):\n",
    "    bert_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2, output_hidden_states=True)\n",
    "    bert_model.to(device)\n",
    "    train_embeddings = get_embeddings(bert_model, tokenized_datasets['train'], test_embedding_file_path, save=False)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=opt_n_estimators, random_state=opt_random_state)\n",
    "    clf.fit(train_embeddings, tokenized_datasets['train']['label']) # X (n_samples, n_features)\n",
    "    \n",
    "    test_embeddings = get_embeddings(bert_model, tokenized_datasets['test'], test_embedding_file_path, save=False)\n",
    "    y_pred = clf.predict(test_embeddings)\n",
    "    \n",
    "    f1 = f1_score(tokenized_datasets['test']['label'], y_pred)\n",
    "    print(f'{checkpoint}: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17530, 768)\n",
      "(4592, 768)\n",
      "finetuned-bert-base-cased/sweep-1-checkpoint-225: 0.8064575988123955\n"
     ]
    }
   ],
   "source": [
    "test_model(\"finetuned-bert-base-cased/sweep-1-checkpoint-225\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17530, 768)\n",
      "(4592, 768)\n",
      "bert-base-cased: 0.7953941541186891\n"
     ]
    }
   ],
   "source": [
    "test_model(\"bert-base-cased\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
