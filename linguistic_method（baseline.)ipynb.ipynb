{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mianhua/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mianhua/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from sklearn.metrics import f1_score\n",
    "import spacy\n",
    "import wandb\n",
    "from collections import Counter\n",
    "# 加载spaCy模型\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = './data/train/'\n",
    "train_label_directory = './data/train_label'\n",
    "test_directory = './data/validation'\n",
    "test_label_directory = './data/validation_label'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_paragraphs(directory, start_id=1, end_id=4200):\n",
    "    documents = {}\n",
    "    for problem_id in range(start_id, end_id + 1):\n",
    "        file_path = os.path.join(directory, f'problem-{problem_id}.txt')\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                paragraphs = file.read().strip().split('\\n')\n",
    "                documents[f'problem-{problem_id}'] = paragraphs\n",
    "        else:\n",
    "            print(f\"File does not exist: {file_path}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "def read_ground_truth(directory, start_id=1, end_id=4200):\n",
    "    labels = {}\n",
    "    for problem_id in range(start_id, end_id + 1):\n",
    "        filename = os.path.join(directory, f'truth-problem-{problem_id}.json')\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                labels[f'problem-{problem_id}'] = data['changes']\n",
    "        else:\n",
    "            print(f\"文件 {filename} 不存在\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "\n",
    "def get_pos_features(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    pos_features = [tag for _, tag in pos_tags]\n",
    "    return pos_features\n",
    "\n",
    "\n",
    "def get_char_ngram_features(text, n=2):\n",
    "    char_ngrams = []\n",
    "    for i in range(len(text) - n + 1):\n",
    "        char_ngrams.append(text[i:i+n])\n",
    "    return char_ngrams\n",
    "\n",
    "def get_text_stats_features(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stats = {\n",
    "        'avg_word_len': np.mean([len(token) for token in tokens]),\n",
    "        'word_count': len(tokens),\n",
    "        'unique_word_count': len(set(tokens)),\n",
    "        'lexical_richness': len(set(tokens)) / len(tokens)\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备的训练集段落对数量: 21919\n",
      "准备的训练集标签对数量: 21919\n",
      "准备的训练集段落对数量: 4592\n",
      "准备的训练集标签对数量: 4592\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_documents = read_paragraphs(train_directory, start_id=1, end_id=4200)\n",
    "train_labels = read_ground_truth(train_label_directory, start_id=1, end_id=4200)\n",
    "\n",
    "test_documents = read_paragraphs(test_directory, start_id=1, end_id=900)\n",
    "test_labels = read_ground_truth(test_label_directory, start_id=1, end_id=900)\n",
    "\n",
    "def generate_dataset(documents, labels):\n",
    "    paragraph_pairs = []\n",
    "    label_set = []\n",
    "    for doc_id, paragraphs in documents.items():\n",
    "        if doc_id in labels:\n",
    "            label_list = labels[doc_id]\n",
    "            num_labels = len(label_list)\n",
    "            num_paragraphs = len(paragraphs)\n",
    "            for i in range(num_paragraphs - 1):\n",
    "                pair = (paragraphs[i], paragraphs[i + 1])\n",
    "                paragraph_pairs.append(' '.join(pair))\n",
    "                if i < num_labels:\n",
    "                    label_set.append(label_list[i])\n",
    "                else:\n",
    "                    label_set.append(0)  # or any other default value you prefer\n",
    "    return paragraph_pairs, label_set\n",
    "\n",
    "\n",
    "train_paragraph_pairs, train_labels_pairs = generate_dataset(train_documents, train_labels)\n",
    "test_paragraph_pairs, test_labels_pairs = generate_dataset(test_documents, test_labels)\n",
    "\n",
    "print(f\"准备的训练集段落对数量: {len(train_paragraph_pairs)}\")\n",
    "print(f\"准备的训练集标签对数量: {len(train_labels_pairs)}\")\n",
    "print(f\"准备的训练集段落对数量: {len(test_paragraph_pairs)}\")\n",
    "print(f\"准备的训练集标签对数量: {len(test_labels_pairs)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vectorizer     = TfidfVectorizer()\n",
    "pos_vectorizer = DictVectorizer()\n",
    "char_ngram_vectorizer = DictVectorizer()\n",
    "text_stats_vectorizer = DictVectorizer()\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(train_paragraph_pairs)\n",
    "X_pos = pos_vectorizer.fit_transform([{0: get_pos_features(' '.join(pair))} for pair in train_paragraph_pairs])\n",
    "X_char_ngrams = char_ngram_vectorizer.fit_transform([{0: get_char_ngram_features(' '.join(pair))} for pair in train_paragraph_pairs])\n",
    "X_text_stats = text_stats_vectorizer.fit_transform([get_text_stats_features(' '.join(pair)) for pair in train_paragraph_pairs])\n",
    "X = np.hstack((X_tfidf.toarray(), X_pos.toarray(), X_char_ngrams.toarray(),X_text_stats.toarray()))\n",
    "y = np.array(train_labels_pairs)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance F1: 0.8111542534415813\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=400)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "print(\"Validation set performance F1:\", f1_score(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
