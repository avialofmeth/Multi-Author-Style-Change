{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_paragraph_files(directory):\n",
    "    paragraphs = []\n",
    "    files = sorted(os.listdir(directory))\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(directory, file), 'r', encoding='utf-8') as f:\n",
    "                paragraphs.append(f.read().strip())\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_simple_prompt(paragraph1, paragraph2):\n",
    "    prompt = (\n",
    "        f\"Given the two texts:\\n\\n\"\n",
    "        f\"Paragraph 1:\\n{paragraph1}\\n\\n\"\n",
    "        f\"Paragraph 2:\\n{paragraph2}\\n\\n\"\n",
    "        f\"Determine if the two texts are written by the same author.\\n\\n\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(paragraph1, paragraph2):\n",
    "    prompt = (\n",
    "        f\"Given the two texts:\\n\\n\"\n",
    "        f\"Paragraph 1:\\n{paragraph1}\\n\\n\"\n",
    "        f\"Paragraph 2:\\n{paragraph2}\\n\\n\"\n",
    "        f\"On a scale of 0 to 1, with 0 indicating low confidence and 1 indicating high confidence, please provide a general assessment of the likelihood that the two texts were written by the same author. Your answer should reflect a moderate level of strictness in scoring, disregarding differences in topic and content. Focus on the following linguistic features to determine if the texts are likely written by the same author\\n\\n\"\n",
    "        f\"1.**Punctuation Style**: Hyphens, brackets, colons, commas, parentheses, quotation marks\\n\"\n",
    "        f\"2.**Lexical and Grammatical Features**: Lexical variation and word choice; Grammatical categories and part of speech usage\\n\"\n",
    "        f\"3.**Sentence Structure and Quantitative Features**: Sentence complexity, length, and arrangement; Coherence and cohesion; Word, clause, and sentence length, frequency, and distributions\\n\"\n",
    "        f\"4.**Text and Discourse Features**: Narrative styles and speech events; Common expressions, idioms, tone and mood\\n\"\n",
    "        f\"5.**Spelling and Typographical Errors*: Spelling mistakes and typographical errors\\n\\n\"\n",
    "        f\"In your analysis, give equal attention to identifying both the commonalities and distinctions between the texts to assess whether they share a similar writing style indicative of the same author.\\n\"\n",
    "        f\"First step: Understand the problem, Give the score of each feature. Then, carry out the plan and solve the problem step by step. Finally, show the overall confidence score, which the AVERAGE of all the 5 features confidence scores above).\\n\\n\"\n",
    "        f\"Respond in a standard JSON format like: for each feature (name it feature1-5), there should be two keys and values (explanation and score), and finally there should be a overall explanation and score.\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cot_prompt(paragraph1, paragraph2):\n",
    "    prompt = (\n",
    "        f\"Given the two texts:\\n\\n\"\n",
    "        f\"Paragraph 1:\\n{paragraph1}\\n\\n\"\n",
    "        f\"Paragraph 2:\\n{paragraph2}\\n\\n\"\n",
    "        f\"On a scale of 0 to 1, with 0 indicating low confidence and 1 indicating high confidence, please provide a general assessment of the likelihood that the two texts were written by the same author. Your answer should reflect a moderate level of strictness in scoring, disregarding differences in topic and content. Focus on the linguistic features to determine if the texts are likely written by the same author\\n\\n\"\n",
    "        f\"In your analysis, give equal attention to identifying both the commonalities and distinctions between the texts to assess whether they share a similar writing style indicative of the same author.\\n\"\n",
    "        f\"Respond in a standard JSON format, with only a brief explanation (key 'explanation') and a score (key 'score').\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\"},\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': f'''{prompt}'''}\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solutions(base_dir, solution_base_dir):\n",
    "    # Get the first x problems, for testing\n",
    "    problem_dirs = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
    "\n",
    "    #for problem_dir in os.listdir(base_dir):\n",
    "    for problem_dir in problem_dirs: \n",
    "        problem_path = os.path.join(base_dir, problem_dir)\n",
    "        if os.path.isdir(problem_path):\n",
    "            print(f\"Processing directory: {problem_dir}\")\n",
    "            paragraphs = read_paragraph_files(problem_path)\n",
    "            \n",
    "            # directory for solutions\n",
    "            result_dir = os.path.join(solution_base_dir, problem_dir)\n",
    "            os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "            for i in range(len(paragraphs) - 1):\n",
    "                paragraph1 = paragraphs[i]\n",
    "                paragraph2 = paragraphs[i + 1]\n",
    "                if paragraph1 and paragraph2:\n",
    "                    #prompt = generate_prompt(paragraph1, paragraph2)\n",
    "                    prompt = generate_cot_prompt(paragraph1, paragraph2)\n",
    "                    result = ask_gpt(prompt)\n",
    "                    \n",
    "                    result_filename = f\"para_{i+1}_and_{i+2}.json\"\n",
    "                    result_filepath = os.path.join(result_dir, result_filename)\n",
    "                    save_result(result_dir, result_filename, result)\n",
    "                    #print(f\"Saved result to {result_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(directory, filename, content):\n",
    "    with open(os.path.join(directory, filename), 'w', encoding='utf-8') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/train_processed'\n",
    "solution_base_dir = 'data/train_solution'\n",
    "\n",
    "generate_solutions(base_dir, solution_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/validation_processed'\n",
    "solution_base_dir = 'data/validation_solution'\n",
    "\n",
    "generate_solutions(base_dir, solution_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate solutions with CoT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/train_processed'\n",
    "solution_base_dir = 'data/train_solution_cot'\n",
    "\n",
    "generate_solutions(base_dir, solution_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/validation_processed'\n",
    "solution_base_dir = 'data/validation_solution_cot'\n",
    "\n",
    "generate_solutions(base_dir, solution_base_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
