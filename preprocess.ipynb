{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_and_split_paragraphs(data_dir):\n",
    "    texts = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as file:\n",
    "                paragraphs = file.read().split('\\n')  \n",
    "                texts.append(paragraphs)\n",
    "                filenames.append(filename)\n",
    "    return texts, filenames\n",
    "\n",
    "def save_paragraphs(texts, filenames, output_dir):\n",
    "    for paragraphs, filename in zip(texts, filenames):\n",
    "        file_base_name = os.path.splitext(filename)[0]\n",
    "        file_dir = os.path.join(output_dir, file_base_name)\n",
    "        os.makedirs(file_dir, exist_ok=True)\n",
    "\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "            paragraph_filename = f'paragraph_{i+1}.txt'\n",
    "            paragraph_filepath = os.path.join(file_dir, paragraph_filename)\n",
    "            with open(paragraph_filepath, 'w', encoding='utf-8') as paragraph_file:\n",
    "                paragraph_file.write(paragraph.strip())\n",
    "\n",
    "def process_data_folders(base_dir):\n",
    "    for folder in ['train', 'validation']:\n",
    "        data_dir = os.path.join(base_dir, folder)\n",
    "        output_dir = os.path.join(base_dir, f'{folder}_processed')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        texts, filenames = read_and_split_paragraphs(data_dir)\n",
    "        save_paragraphs(texts, filenames, output_dir)\n",
    "\n",
    "base_data_dir = 'data'\n",
    "process_data_folders(base_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split_paragraphs(data_dir):\n",
    "    texts = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as file:\n",
    "                paragraphs = []\n",
    "                current_paragraph = ''\n",
    "                for line in file:\n",
    "                    stripped_line = line.strip()\n",
    "                    if stripped_line:\n",
    "                        if line.startswith(' '):  # Check for indentation\n",
    "                            current_paragraph += ' ' + stripped_line\n",
    "                        else:\n",
    "                            if current_paragraph:\n",
    "                                paragraphs.append(current_paragraph)\n",
    "                            current_paragraph = stripped_line\n",
    "                    else:\n",
    "                        if current_paragraph:\n",
    "                            paragraphs.append(current_paragraph)\n",
    "                            current_paragraph = ''\n",
    "                if current_paragraph:  # Append the last paragraph if it exists\n",
    "                    paragraphs.append(current_paragraph)\n",
    "                texts.append(paragraphs)\n",
    "                filenames.append(filename)\n",
    "    return texts, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_paragraphs(texts, filenames, output_dir):\n",
    "    for paragraphs, filename in zip(texts, filenames):\n",
    "        file_base_name = os.path.splitext(filename)[0]\n",
    "        file_dir = os.path.join(output_dir, file_base_name)\n",
    "        os.makedirs(file_dir, exist_ok=True)\n",
    "\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "            paragraph_filename = f'paragraph_{i+1}.txt'\n",
    "            paragraph_filepath = os.path.join(file_dir, paragraph_filename)\n",
    "            with open(paragraph_filepath, 'w', encoding='utf-8') as paragraph_file:\n",
    "                paragraph_file.write(paragraph.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_folders(base_dir):\n",
    "    for folder in ['train', 'validation']:\n",
    "        data_dir = os.path.join(base_dir, folder)\n",
    "        output_dir = os.path.join(base_dir, f'{folder}_processed')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        texts, filenames = read_and_split_paragraphs(data_dir)\n",
    "        save_paragraphs(texts, filenames, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = 'data'\n",
    "process_data_folders(base_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test problem-3403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: problem-3043.txt\n",
      "Paragraph 1: Did you expect anything else but downvotes on this sub if you dare to stray from the Western MSM cool-aid narrative? lol.\n",
      "Paragraph 2: Of course, that's what they always do. That is why they were and are war mongering around the world, creating conflicts where there were none.\n",
      "Paragraph 3: Phippines literally tried to be chinas ally and china doubled down on south china sea claims. China has themselves to blame.\n",
      "Paragraph 4: What would scare the shit out of you is the Chinese military starting up a war with Taiwan, similar to the one Russia has started with Ukraine. The US has already stated that they would get involved directly with a conflict over Taiwan, so it’s best to keep the Chinese military at bay through deterrence, in case they decide to get too ballsy.\n",
      "Paragraph 5: \" The US already had limited access to five sites under the Enhanced Defence Cooperation Agreement (EDCA) - the new additions and expanded access, according to a statement from Washinon, will \"allow more rapid support for humanitarian and climate-related disasters in the Philippines, and respond to other shared challenges\" \".\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def read_and_split_paragraphs(file_path):\n",
    "    texts = []\n",
    "    filenames = []\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            paragraphs = []\n",
    "            current_paragraph = ''\n",
    "            for line in file:\n",
    "                stripped_line = line.strip()\n",
    "                if stripped_line:\n",
    "                    if line.startswith(' '):  # Check for indentation\n",
    "                        current_paragraph += ' ' + stripped_line\n",
    "                    else:\n",
    "                        if current_paragraph:\n",
    "                            paragraphs.append(current_paragraph)\n",
    "                        current_paragraph = stripped_line\n",
    "                else:\n",
    "                    if current_paragraph:\n",
    "                        paragraphs.append(current_paragraph)\n",
    "                        current_paragraph = ''\n",
    "            if current_paragraph:  # Append the last paragraph if it exists\n",
    "                paragraphs.append(current_paragraph)\n",
    "            texts.append(paragraphs)\n",
    "            filenames.append(os.path.basename(file_path))\n",
    "    return texts, filenames\n",
    "\n",
    "# 设置测试文件路径\n",
    "test_file_path = 'data/train/problem-3043.txt'\n",
    "\n",
    "# 测试函数\n",
    "texts, filenames = read_and_split_paragraphs(test_file_path)\n",
    "\n",
    "# 打印结果\n",
    "for filename, paragraphs in zip(filenames, texts):\n",
    "    print(f\"Filename: {filename}\")\n",
    "    for i, paragraph in enumerate(paragraphs, 1):\n",
    "        print(f\"Paragraph {i}: {paragraph}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
